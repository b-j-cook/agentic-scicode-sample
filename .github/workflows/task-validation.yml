name: Task Validation

on:
  pull_request:
    paths:
      - 'tasks/**'
      - '!tasks/_template/**'
      - '!tasks/README.md'
  
  push:
    branches:
      - main
    paths:
      - 'tasks/**'
      - '!tasks/_template/**'
      - '!tasks/README.md'
  
  workflow_dispatch:
    inputs:
      task_dir:
        description: 'Path to task directory to validate (e.g., tasks/pde_sharp)'
        required: false
        type: string

permissions:
  contents: read

jobs:
  validate-and-test:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -e .
      
      - name: Get changed tasks
        id: get-tasks
        if: github.event_name != 'workflow_dispatch'
        run: |
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            BASE_SHA="${{ github.event.pull_request.base.sha }}"
          else
            # For push events, compare with previous commit
            BASE_SHA="${{ github.event.before }}"
          fi
          
          # Get unique task directories that were modified
          TASKS=$(git diff --name-only $BASE_SHA ${{ github.sha }} | \
            grep '^tasks/' | \
            grep -v '^tasks/_template/' | \
            grep -v '^tasks/README.md' | \
            sed 's|^\(tasks/[^/]*\)/.*|\1|' | \
            sort -u || true)
          
          if [ -z "$TASKS" ]; then
            echo "No task directories changed"
            echo "tasks=" >> $GITHUB_OUTPUT
          else
            echo "Found changed tasks:"
            echo "$TASKS"
            # Convert newlines to spaces
            TASKS_INLINE=$(echo "$TASKS" | tr '\n' ' ')
            echo "tasks=$TASKS_INLINE" >> $GITHUB_OUTPUT
          fi
      
      - name: Set manual task
        id: set-manual-task
        if: github.event_name == 'workflow_dispatch' && inputs.task_dir != ''
        run: |
          echo "tasks=${{ inputs.task_dir }}" >> $GITHUB_OUTPUT
      
      - name: Validate tasks
        id: validate
        run: |
          # Determine which tasks to validate
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            TASKS="${{ steps.set-manual-task.outputs.tasks }}"
          else
            TASKS="${{ steps.get-tasks.outputs.tasks }}"
          fi
          
          if [ -z "$TASKS" ]; then
            echo "No tasks to validate"
            exit 0
          fi
          
          echo "=========================================="
          echo "Validating tasks..."
          echo "=========================================="
          
          FAILED=0
          for task in $TASKS; do
            echo ""
            echo "Validating: $task"
            echo "---"
            if ! task validate "$task"; then
              echo "❌ Validation failed for $task"
              FAILED=1
            else
              echo "✓ Validation passed for $task"
            fi
          done
          
          if [ $FAILED -eq 1 ]; then
            echo ""
            echo "❌ One or more tasks failed validation"
            exit 1
          fi
          
          echo ""
          echo "✓ All tasks passed validation"
      
      - name: Compile and test tasks (gold mode)
        id: test
        env:
          # Dummy key required by inspect-ai even in gold mode
          OPENAI_API_KEY: "sk-dummy-key-for-gold-mode"
        run: |
          # Determine which tasks to test
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            TASKS="${{ steps.set-manual-task.outputs.tasks }}"
          else
            TASKS="${{ steps.get-tasks.outputs.tasks }}"
          fi
          
          if [ -z "$TASKS" ]; then
            echo "No tasks to test"
            exit 0
          fi
          
          echo "=========================================="
          echo "Testing tasks in GOLD mode (100% required)"
          echo "=========================================="
          
          FAILED=0
          for task in $TASKS; do
            echo ""
            echo "=========================================="
            echo "Processing: $task"
            echo "=========================================="
            
            # Step 1: Compile the task
            echo ""
            echo "Step 1: Compiling task..."
            echo "---"
            if ! task compile "$task"; then
              echo "❌ Compilation failed for $task"
              FAILED=1
              continue
            fi
            echo "✓ Compiled successfully"
            
            # Get problem ID from the compiled output
            PROBLEM_ID=$(python3 -c "
          import yaml
          with open('$task/problem.yaml') as f:
              data = yaml.safe_load(f)
          print(data['problem_id'])
          ")
            echo "Problem ID: $PROBLEM_ID"
            
            # Count expected steps
            STEP_COUNT=$(python3 -c "
          import yaml
          with open('$task/problem.yaml') as f:
              data = yaml.safe_load(f)
          print(len(data.get('steps', [])))
          ")
            echo "Expected steps: $STEP_COUNT"
            
            # Step 2: Run evaluation in GOLD mode
            echo ""
            echo "Step 2: Running gold mode evaluation..."
            echo "---"
            
            cd eval/inspect_ai
            
            # Run inspect and capture output
            OUTPUT=$(inspect eval scicode.py \
              --model "openai/gpt-4o" \
              -T "mode=gold" \
              -T "problems=$PROBLEM_ID" \
              -T "output_dir=../../tmp_test" \
              -T "local_jsonl=../data/problems.jsonl" \
              -T "h5py_file=../data/test_data.h5" 2>&1) || true
            
            echo "$OUTPUT"
            
            # Check for 100% pass rate in gold mode
            # Gold mode should always pass all steps since it uses the reference solution
            if echo "$OUTPUT" | grep -qE "accuracy: 1\.0|100%|1/1|sub_problem_correctness: 1(\.0)?|Problem Correctness/mean: 1(\.0)?"; then
              echo "✓ Gold mode test passed with 100% accuracy for $task"
            else
              # Parse the accuracy from output
              ACCURACY=$(echo "$OUTPUT" | grep -oE "(accuracy|sub_problem_correctness): [0-9.]+" | tail -1 | grep -oE "[0-9.]+") || ACCURACY="unknown"
              
              if [ "$ACCURACY" = "1" ] || [ "$ACCURACY" = "1.0" ]; then
                echo "✓ Gold mode test passed with 100% accuracy for $task"
              else
                echo "❌ Gold mode test FAILED for $task"
                echo "   Expected: 100% accuracy (gold mode should always pass)"
                echo "   Got: $ACCURACY"
                echo ""
                echo "   This indicates a problem with the task definition:"
                echo "   - Check that _gold_* functions are correct"
                echo "   - Check that test_cases() are properly defined"
                echo "   - Check that dependencies are listed in problem.yaml"
                FAILED=1
              fi
            fi
            cd ../..
          done
          
          if [ $FAILED -eq 1 ]; then
            echo ""
            echo "=========================================="
            echo "❌ GOLD MODE TESTS FAILED"
            echo "=========================================="
            echo "Gold mode uses the reference solutions from _gold_* functions."
            echo "If gold mode fails, the task definition has errors."
            echo ""
            echo "Common issues:"
            echo "  1. Bug in _gold_* solution code"
            echo "  2. Missing dependencies in problem.yaml"
            echo "  3. Incorrect test_cases() assertions"
            echo "  4. Helper functions not properly prefixed with _"
            exit 1
          fi
          
          echo ""
          echo "=========================================="
          echo "✓ All tasks passed gold mode testing (100%)"
          echo "=========================================="
      
      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: task-test-results
          path: |
            tmp_test/
            eval/data/problems.jsonl
            eval/data/test_data.h5
          if-no-files-found: ignore
