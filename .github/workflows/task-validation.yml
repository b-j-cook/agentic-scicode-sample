name: Task Validation

on:
  pull_request:
    paths:
      - 'tasks/**'
      - '!tasks/_template/**'
      - '!tasks/README.md'
  
  push:
    branches:
      - main
    paths:
      - 'tasks/**'
      - '!tasks/_template/**'
      - '!tasks/README.md'
  
  workflow_dispatch:
    inputs:
      task_dir:
        description: 'Path to task directory to validate (e.g., tasks/pde_sharp)'
        required: false
        type: string
      model:
        description: 'Model to use for testing (e.g., openai/gpt-4o)'
        required: false
        default: 'openai/gpt-4o'
        type: string

permissions:
  contents: read

env:
  # Default model for automated runs
  DEFAULT_MODEL: 'openai/gpt-4o'

jobs:
  validate-and-test:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -e .
      
      - name: Get changed tasks
        id: get-tasks
        if: github.event_name != 'workflow_dispatch'
        run: |
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            BASE_SHA="${{ github.event.pull_request.base.sha }}"
          else
            # For push events, compare with previous commit
            BASE_SHA="${{ github.event.before }}"
          fi
          
          # Get unique task directories that were modified
          TASKS=$(git diff --name-only $BASE_SHA ${{ github.sha }} | \
            grep '^tasks/' | \
            grep -v '^tasks/_template/' | \
            grep -v '^tasks/README.md' | \
            sed 's|^\(tasks/[^/]*\)/.*|\1|' | \
            sort -u || true)
          
          if [ -z "$TASKS" ]; then
            echo "No task directories changed"
            echo "tasks=" >> $GITHUB_OUTPUT
          else
            echo "Found changed tasks:"
            echo "$TASKS"
            # Convert newlines to spaces
            TASKS_INLINE=$(echo "$TASKS" | tr '\n' ' ')
            echo "tasks=$TASKS_INLINE" >> $GITHUB_OUTPUT
          fi
      
      - name: Set manual task
        id: set-manual-task
        if: github.event_name == 'workflow_dispatch' && inputs.task_dir != ''
        run: |
          echo "tasks=${{ inputs.task_dir }}" >> $GITHUB_OUTPUT
      
      - name: Validate tasks
        id: validate
        run: |
          # Determine which tasks to validate
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            TASKS="${{ steps.set-manual-task.outputs.tasks }}"
          else
            TASKS="${{ steps.get-tasks.outputs.tasks }}"
          fi
          
          if [ -z "$TASKS" ]; then
            echo "No tasks to validate"
            exit 0
          fi
          
          echo "=========================================="
          echo "Validating tasks..."
          echo "=========================================="
          
          FAILED=0
          for task in $TASKS; do
            echo ""
            echo "Validating: $task"
            echo "---"
            if ! task validate "$task"; then
              echo "❌ Validation failed for $task"
              FAILED=1
            else
              echo "✓ Validation passed for $task"
            fi
          done
          
          if [ $FAILED -eq 1 ]; then
            echo ""
            echo "❌ One or more tasks failed validation"
            exit 1
          fi
          
          echo ""
          echo "✓ All tasks passed validation"
      
      - name: Compile and test tasks
        id: test
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          # Determine which tasks to test
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            TASKS="${{ steps.set-manual-task.outputs.tasks }}"
            MODEL="${{ inputs.model || env.DEFAULT_MODEL }}"
          else
            TASKS="${{ steps.get-tasks.outputs.tasks }}"
            MODEL="${{ env.DEFAULT_MODEL }}"
          fi
          
          if [ -z "$TASKS" ]; then
            echo "No tasks to test"
            exit 0
          fi
          
          echo "=========================================="
          echo "Testing tasks with model: $MODEL"
          echo "=========================================="
          
          FAILED=0
          for task in $TASKS; do
            echo ""
            echo "=========================================="
            echo "Processing: $task"
            echo "=========================================="
            
            # Step 1: Compile the task
            echo ""
            echo "Step 1: Compiling task..."
            echo "---"
            if ! task compile "$task"; then
              echo "❌ Compilation failed for $task"
              FAILED=1
              continue
            fi
            echo "✓ Compiled successfully"
            
            # Get problem ID from the compiled output
            PROBLEM_ID=$(python3 -c "
          import yaml
          with open('$task/problem.yaml') as f:
              data = yaml.safe_load(f)
          print(data['problem_id'])
          ")
            echo "Problem ID: $PROBLEM_ID"
            
            # Step 2: Run evaluation with the model
            echo ""
            echo "Step 2: Running evaluation with $MODEL..."
            echo "---"
            
            cd eval/inspect_ai
            if ! inspect eval scicode.py \
              --model "$MODEL" \
              -T "mode=normal" \
              -T "problems=$PROBLEM_ID" \
              -T "output_dir=../../tmp_test" \
              -T "local_jsonl=../data/problems.jsonl" \
              -T "h5py_file=../data/test_data.h5"; then
              echo "❌ Test failed for $task"
              FAILED=1
            else
              echo "✓ Test passed for $task"
            fi
            cd ../..
          done
          
          if [ $FAILED -eq 1 ]; then
            echo ""
            echo "❌ One or more tasks failed testing"
            exit 1
          fi
          
          echo ""
          echo "✓ All tasks passed testing"
      
      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: task-test-results
          path: |
            tmp_test/
            eval/data/problems.jsonl
            eval/data/test_data.h5
          if-no-files-found: ignore
